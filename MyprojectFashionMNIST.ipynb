{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " MyprojectFashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **This project is using keras**"
      ],
      "metadata": {
        "id": "MtPRUtKcyG-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## what we are gonna do -->\n",
        "Train Convolutional Neural Network on 60,000 Fashion-MNIST Images (data in NP array)\n",
        " \n",
        "Test Convolutional Neural Network on 10,000 Fashion-MNIST Images (data in NP array)"
      ],
      "metadata": {
        "id": "Y0nTYN7Yvl1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# from torch.utils.data import Dataset\n",
        "import keras # to build Neural Network"
      ],
      "metadata": {
        "id": "ej1jnvvFvuaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load data \n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.fashion_mnist.load_data() # load dataset from  keras\n",
        " \n",
        "# Print shape of Data\n",
        " \n",
        "X_train.shape, y_train.shape, \"******\", X_test.shape, y_test.shape\n",
        " \n",
        "X_train[0] # image data in 2d numpy array shape 28x28 pixel\n",
        " \n",
        "y_train[0] #9 => Ankle boot\n",
        " \n",
        "class_labels = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]\n",
        "'''\n",
        "0 => T-shirt/top \n",
        "1 => Trouser \n",
        "2 => Pullover \n",
        "3 => Dress \n",
        "4 => Coat \n",
        "5 => Sandal \n",
        "6 => Shirt \n",
        "7 => Sneaker \n",
        "8 => Bag \n",
        "9 => Ankle boot '''"
      ],
      "metadata": {
        "id": "GoTqNMLYx3ps",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "92b56c57-250f-45e6-b728-4eaf0809fd2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1f1f503262c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# load dataset from  keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Print shape of Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras' has no attribute 'datasets'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#show image\n",
        "plt.imshow(X_train[0], cmap='Greys')\n",
        " \n",
        "plt.figure(figsize=(16,16))\n",
        " \n",
        "j=1\n",
        "for i in np.random.randint(0, 1000, 25):\n",
        "  plt.subplot(5,5,j); j+=1\n",
        "  plt.imshow(X_train[i], cmap=\"Greys\")\n",
        "  plt.axis('off') # off the axis\n",
        "  plt.title('{} / {}'.format(class_labels[y_train[i]], y_train[i]))"
      ],
      "metadata": {
        "id": "FaE471rMyRdt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "325c416e-fefb-4b8d-cd7f-fb52a85cb12b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8ab71f905158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#show image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change Dimension\n",
        "\n",
        "X_train.shape\n",
        " \n",
        "X_train.ndim\n",
        " \n",
        "# expected conv2d_input to have 4 dimensions, but got array with shape (28, 28, 1)\n",
        "# so we have increase the dimention 3 to 4\n",
        "X_train = np.expand_dims(X_train, -1)\n",
        "X_test = np.expand_dims(X_test, -1)\n",
        " \n",
        "# ref: https://numpy.org/doc/stable/reference/generated/numpy.expand_dims.html\n",
        " \n",
        "X_train.ndim"
      ],
      "metadata": {
        "id": "cRr8uYqmyXv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#eature Scaling \n",
        "\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "metadata": {
        "id": "L38ttl8UycwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split Dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size= 0.2, random_state=2020)\n",
        " \n",
        "X_train.shape,  y_train.shape, X_validation.shape, y_validation.shape"
      ],
      "metadata": {
        "id": "Lkf5FqJLyoID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN Model Building \n",
        "\n",
        "cnn_model = keras.models.Sequential([\n",
        "                         keras.layers.Conv2D(filters=32, kernel_size=3, strides=(1,1), padding='valid',activation= 'relu', input_shape=[28,28,1]),\n",
        "                         keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                         keras.layers.Flatten(),\n",
        "                         keras.layers.Dense(units=128, activation='relu'),\n",
        "                         keras.layers.Dense(units=10, activation='softmax')\n",
        "])\n",
        " \n",
        "cnn_model.summary() # get the summary of model\n",
        " \n",
        "# complie the model\n",
        "cnn_model.compile(optimizer='adam', loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "# train cnn model\n",
        "cnn_model.fit(X_train, y_train, epochs=10, batch_size=512, verbose=1, validation_data=(X_validation, y_validation))\n"
      ],
      "metadata": {
        "id": "JVH35NXTyyws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test and Evaluate the Model \n",
        "\n",
        "y_pred = cnn_model.predict(X_test)\n",
        "y_pred.round(2)\n",
        " \n",
        "y_test\n",
        " \n",
        "cnn_model.evaluate(X_test, y_test)\n",
        " \n",
        "\"\"\"# Visualize output\n",
        " \n",
        "plt.figure(figsize=(16,16))\n",
        " \n",
        "j=1\n",
        "for i in np.random.randint(0, 1000,25):\n",
        "  plt.subplot(5,5, j); j+=1\n",
        "  plt.imshow(X_test[i].reshape(28,28), cmap = 'Greys')\n",
        "  plt.title('Actual = {} / {} \\nPredicted = {} / {}'.format(class_labels[y_test[i]], y_test[i], class_labels[np.argmax(y_pred[i])],np.argmax(y_pred[i])))\n",
        "  plt.axis('off')\n",
        "\"\"\"\n",
        " \n",
        "plt.figure(figsize=(16,30))\n",
        " \n",
        "j=1\n",
        "for i in np.random.randint(0, 1000,60):\n",
        "  plt.subplot(10,6, j); j+=1\n",
        "  plt.imshow(X_test[i].reshape(28,28), cmap = 'Greys')\n",
        "  plt.title('Actual = {} / {} \\nPredicted = {} / {}'.format(class_labels[y_test[i]], y_test[i], class_labels[np.argmax(y_pred[i])],np.argmax(y_pred[i])))\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "fEoU1fxnzOgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        " \n",
        "plt.figure(figsize=(16,9))\n",
        "y_pred_labels = [ np.argmax(label) for label in y_pred ]\n",
        "cm = confusion_matrix(y_test, y_pred_labels)\n",
        " \n",
        "# show cm \n",
        "sns.heatmap(cm, annot=True, fmt='d',xticklabels=class_labels, yticklabels=class_labels)\n",
        " \n",
        "from sklearn.metrics import classification_report\n",
        "cr= classification_report(y_test, y_pred_labels, target_names=class_labels)\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "O_xDCeVazoSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save model\n",
        "\n",
        "cnn_model.save('fashion_mnist_cnn_model.h5') # Save model\n",
        " \n",
        "# Load model\n",
        "fashion_mnist_cnn_model = keras.models.load_model('fashion_mnist_cnn_model.h5')\n",
        " \n",
        "Y_pred_sample = fashion_mnist_cnn_model.predict(np.expand_dims(X_test[0], axis=0)).round(2)\n",
        "Y_pred_sample\n",
        " \n",
        "np.argmax(Y_pred_sample[0])\n",
        " \n",
        "y_test[0]"
      ],
      "metadata": {
        "id": "GT0z6X0QzvDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Complex CNN\n",
        "\n",
        "cnn_model2 = keras.models.Sequential([\n",
        "                         keras.layers.Conv2D(filters=32, kernel_size=3, strides=(1,1), padding='valid',activation= 'relu', input_shape=[28,28,1]),\n",
        "                         keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                         keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2), padding='same', activation='relu'),\n",
        "                         keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                         keras.layers.Flatten(),\n",
        "                         keras.layers.Dense(units=128, activation='relu'),\n",
        "                         keras.layers.Dropout(0.25),\n",
        "                         keras.layers.Dense(units=256, activation='relu'),\n",
        "                         keras.layers.Dropout(0.25),\n",
        "                         keras.layers.Dense(units=128, activation='relu'),\n",
        "                         keras.layers.Dense(units=10, activation='softmax')\n",
        "                         ])\n",
        " \n",
        "# complie the model\n",
        "cnn_model2.compile(optimizer='adam', loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "#Train the Model\n",
        "cnn_model2.fit(X_train, y_train, epochs=20, batch_size=512, verbose=1, validation_data=(X_validation, y_validation))\n",
        " \n",
        "cnn_model2.save('fashion_mnist_cnn_model2.h5')"
      ],
      "metadata": {
        "id": "KLkiK5Hoz-Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build Very Complex CNN model\n",
        "\n",
        "#Building CNN model\n",
        "cnn_model3 = keras.models.Sequential([\n",
        "                         keras.layers.Conv2D(filters=64, kernel_size=3, strides=(1,1), padding='valid',activation= 'relu', input_shape=[28,28,1]),\n",
        "                         keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                         keras.layers.Conv2D(filters=128, kernel_size=3, strides=(2,2), padding='same', activation='relu'),\n",
        "                         keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                         keras.layers.Conv2D(filters=64, kernel_size=3, strides=(2,2), padding='same', activation='relu'),\n",
        "                         keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                         keras.layers.Flatten(),\n",
        "                         keras.layers.Dense(units=128, activation='relu'),\n",
        "                         keras.layers.Dropout(0.25),\n",
        "                         keras.layers.Dense(units=256, activation='relu'),\n",
        "                         keras.layers.Dropout(0.5),\n",
        "                         keras.layers.Dense(units=256, activation='relu'),\n",
        "                         keras.layers.Dropout(0.25),                        \n",
        "                         keras.layers.Dense(units=128, activation='relu'),\n",
        "                         keras.layers.Dropout(0.10),                         \n",
        "                         keras.layers.Dense(units=10, activation='softmax')\n",
        "                         ])\n",
        " \n",
        "# complie the model\n",
        "cnn_model3.compile(optimizer='adam', loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        " \n",
        "#Train the Model\n",
        "cnn_model3.fit(X_train, y_train, epochs=50, batch_size=512, verbose=1, validation_data=(X_validation, y_validation))\n",
        " \n",
        "cnn_model3.save('fashion_mnist_cnn_model3.h5')\n",
        " \n",
        "cnn_model3.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "oGxdAraB0FwT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}